{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion de PDF a imagenes \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, output_dir, dpi=400):\n",
    "    \"\"\"\n",
    "    Convierte todas las páginas de un PDF a imágenes PNG.\n",
    "    Args:\n",
    "        pdf_path (str): Ruta al archivo PDF.\n",
    "        output_dir (str): Carpeta donde se guardarán las imágenes.\n",
    "        dpi (int): Resolución para la conversión. 300 suele ser un buen valor.\n",
    "    Returns:\n",
    "        List[str]: Lista de rutas a las imágenes generadas.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # pages será una lista de PIL Images\n",
    "    pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "\n",
    "    image_paths = []\n",
    "    for i, page in enumerate(pages):\n",
    "        image_name = f\"page_{i+1}.png\"\n",
    "        out_path = os.path.join(output_dir, image_name)\n",
    "        # Guardar la imagen en PNG\n",
    "        page.save(out_path, \"PNG\")\n",
    "        image_paths.append(out_path)\n",
    "\n",
    "    return image_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el modelo de TATR de Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pibezx/miniconda3/envs/chatbot_ml/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Using a slow image processor as `use_fast` is unset and a slow processor was saved with this model. `use_fast=True` will be the default behavior in v4.48, even if the model was saved with a slow processor. This will result in minor differences in outputs. You'll still be able to use a slow processor with `use_fast=False`.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TableTransformerForObjectDetection(\n",
       "  (model): TableTransformerModel(\n",
       "    (backbone): TableTransformerConvModel(\n",
       "      (conv_encoder): TableTransformerConvEncoder(\n",
       "        (model): ResNetBackbone(\n",
       "          (embedder): ResNetEmbeddings(\n",
       "            (embedder): ResNetConvLayer(\n",
       "              (convolution): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "              (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "              (activation): ReLU()\n",
       "            )\n",
       "            (pooler): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "          )\n",
       "          (encoder): ResNetEncoder(\n",
       "            (stages): ModuleList(\n",
       "              (0): ResNetStage(\n",
       "                (layers): Sequential(\n",
       "                  (0): ResNetBasicLayer(\n",
       "                    (shortcut): Identity()\n",
       "                    (layer): Sequential(\n",
       "                      (0): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): ReLU()\n",
       "                      )\n",
       "                      (1): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): Identity()\n",
       "                      )\n",
       "                    )\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                  (1): ResNetBasicLayer(\n",
       "                    (shortcut): Identity()\n",
       "                    (layer): Sequential(\n",
       "                      (0): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): ReLU()\n",
       "                      )\n",
       "                      (1): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): Identity()\n",
       "                      )\n",
       "                    )\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (1): ResNetStage(\n",
       "                (layers): Sequential(\n",
       "                  (0): ResNetBasicLayer(\n",
       "                    (shortcut): ResNetShortCut(\n",
       "                      (convolution): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                      (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                    )\n",
       "                    (layer): Sequential(\n",
       "                      (0): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): ReLU()\n",
       "                      )\n",
       "                      (1): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): Identity()\n",
       "                      )\n",
       "                    )\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                  (1): ResNetBasicLayer(\n",
       "                    (shortcut): Identity()\n",
       "                    (layer): Sequential(\n",
       "                      (0): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): ReLU()\n",
       "                      )\n",
       "                      (1): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): Identity()\n",
       "                      )\n",
       "                    )\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (2): ResNetStage(\n",
       "                (layers): Sequential(\n",
       "                  (0): ResNetBasicLayer(\n",
       "                    (shortcut): ResNetShortCut(\n",
       "                      (convolution): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                      (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                    )\n",
       "                    (layer): Sequential(\n",
       "                      (0): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): ReLU()\n",
       "                      )\n",
       "                      (1): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): Identity()\n",
       "                      )\n",
       "                    )\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                  (1): ResNetBasicLayer(\n",
       "                    (shortcut): Identity()\n",
       "                    (layer): Sequential(\n",
       "                      (0): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): ReLU()\n",
       "                      )\n",
       "                      (1): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): Identity()\n",
       "                      )\n",
       "                    )\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "              (3): ResNetStage(\n",
       "                (layers): Sequential(\n",
       "                  (0): ResNetBasicLayer(\n",
       "                    (shortcut): ResNetShortCut(\n",
       "                      (convolution): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "                      (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                    )\n",
       "                    (layer): Sequential(\n",
       "                      (0): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): ReLU()\n",
       "                      )\n",
       "                      (1): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): Identity()\n",
       "                      )\n",
       "                    )\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                  (1): ResNetBasicLayer(\n",
       "                    (shortcut): Identity()\n",
       "                    (layer): Sequential(\n",
       "                      (0): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): ReLU()\n",
       "                      )\n",
       "                      (1): ResNetConvLayer(\n",
       "                        (convolution): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "                        (normalization): TableTransformerFrozenBatchNorm2d()\n",
       "                        (activation): Identity()\n",
       "                      )\n",
       "                    )\n",
       "                    (activation): ReLU()\n",
       "                  )\n",
       "                )\n",
       "              )\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (position_embedding): TableTransformerSinePositionEmbedding()\n",
       "    )\n",
       "    (input_projection): Conv2d(512, 256, kernel_size=(1, 1), stride=(1, 1))\n",
       "    (query_position_embeddings): Embedding(15, 256)\n",
       "    (encoder): TableTransformerEncoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TableTransformerEncoderLayer(\n",
       "          (self_attn): TableTransformerAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (activation_fn): ReLU()\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "    (decoder): TableTransformerDecoder(\n",
       "      (layers): ModuleList(\n",
       "        (0-5): 6 x TableTransformerDecoderLayer(\n",
       "          (self_attn): TableTransformerAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (activation_fn): ReLU()\n",
       "          (self_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (encoder_attn): TableTransformerAttention(\n",
       "            (k_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (v_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (q_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "            (out_proj): Linear(in_features=256, out_features=256, bias=True)\n",
       "          )\n",
       "          (encoder_attn_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "          (fc1): Linear(in_features=256, out_features=2048, bias=True)\n",
       "          (fc2): Linear(in_features=2048, out_features=256, bias=True)\n",
       "          (final_layer_norm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "        )\n",
       "      )\n",
       "      (layernorm): LayerNorm((256,), eps=1e-05, elementwise_affine=True)\n",
       "    )\n",
       "  )\n",
       "  (class_labels_classifier): Linear(in_features=256, out_features=3, bias=True)\n",
       "  (bbox_predictor): TableTransformerMLPPredictionHead(\n",
       "    (layers): ModuleList(\n",
       "      (0-1): 2 x Linear(in_features=256, out_features=256, bias=True)\n",
       "      (2): Linear(in_features=256, out_features=4, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "model_name = \"microsoft/table-transformer-detection\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name, revision = \"no_timm\")  #no_timm se usa para evitar problemas \n",
    "model = AutoModelForObjectDetection.from_pretrained(model_name, revision = \"no_timm\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deteccion de tablas en cada imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def detect_tables_in_image(image_path, confidence_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Detecta tablas en una imagen usando Table Transformer (detección).\n",
    "    Args:\n",
    "        image_path (str): Ruta a la imagen PNG/JPG.\n",
    "        confidence_threshold (float): Umbral de confianza para filtrar predicciones.\n",
    "    Returns:\n",
    "        List[dict]: Lista de tablas detectadas, cada dict contiene 'score' y 'box' con coords (xmin, ymin, xmax, ymax).\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    # Preprocesar la imagen\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Postprocesar\n",
    "    result = processor.post_process_object_detection(outputs, threshold=confidence_threshold)[0]\n",
    "\n",
    "    detections = []\n",
    "    for score, label, box in zip(result[\"scores\"], result[\"labels\"], result[\"boxes\"]):\n",
    "        if label == 1:  # 1 es la clase 'table' en este modelo\n",
    "            # box es [xmin, ymin, xmax, ymax]\n",
    "            det = {\n",
    "                \"score\": float(score.cpu().numpy()),\n",
    "                \"box\": [float(x) for x in box.cpu().numpy()]\n",
    "            }\n",
    "            detections.append(det)\n",
    "    return detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_table_images(image_path, detections, output_dir):\n",
    "    \"\"\"\n",
    "    Recorta y guarda las regiones de tabla detectadas en 'detections'.\n",
    "    Args:\n",
    "        image_path (str): Ruta a la imagen original.\n",
    "        detections (List[dict]): Lista de tablas con su 'box'.\n",
    "        output_dir (str): Carpeta donde guardar los recortes.\n",
    "    Returns:\n",
    "        List[str]: Rutas de las imágenes recortadas de cada tabla.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    table_paths = []\n",
    "    for i, det in enumerate(detections):\n",
    "        box = det[\"box\"]  # [xmin, ymin, xmax, ymax]\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        # Recortar\n",
    "        cropped = image.crop((xmin, ymin, xmax, ymax))\n",
    "        table_path = os.path.join(output_dir, f\"table_{i+1}.png\")\n",
    "        cropped.save(table_path, \"PNG\")\n",
    "        table_paths.append(table_path)\n",
    "    return table_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "PDFPageCountError",
     "evalue": "Unable to get page count.\nSyntax Warning: May not be a PDF file (continuing anyway)\nSyntax Error: Couldn't find trailer dictionary\nSyntax Error: Couldn't find trailer dictionary\nSyntax Error: Couldn't read xref table\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[0;32m~/miniconda3/envs/chatbot_ml/lib/python3.10/site-packages/pdf2image/pdf2image.py:602\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[0;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[1;32m    601\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPages\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m d:\n\u001b[0;32m--> 602\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m\n\u001b[1;32m    604\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m d\n",
      "\u001b[0;31mValueError\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mPDFPageCountError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[7], line 36\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;18m__name__\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__main__\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m     35\u001b[0m     pdf_file \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/Mazda\u001b[39m\u001b[38;5;124m\"\u001b[39m \n\u001b[0;32m---> 36\u001b[0m     result_tables \u001b[38;5;241m=\u001b[39m \u001b[43mprocess_pdf_for_tables\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_file\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbase_output_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43ml200_output\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m400\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     37\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTablas detectadas:\u001b[39m\u001b[38;5;124m\"\u001b[39m, result_tables)\n",
      "Cell \u001b[0;32mIn[7], line 10\u001b[0m, in \u001b[0;36mprocess_pdf_for_tables\u001b[0;34m(pdf_path, base_output_dir, dpi)\u001b[0m\n\u001b[1;32m      7\u001b[0m pages_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_output_dir, pdf_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpages\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      8\u001b[0m tables_dir \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(base_output_dir, pdf_name, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtables\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m page_images \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_pdf_to_images\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpages_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m all_tables \u001b[38;5;241m=\u001b[39m []  \u001b[38;5;66;03m# Para almacenar info de cada tabla\u001b[39;00m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m page_image \u001b[38;5;129;01min\u001b[39;00m page_images:\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;66;03m# 2) Detectar tablas\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[3], line 18\u001b[0m, in \u001b[0;36mconvert_pdf_to_images\u001b[0;34m(pdf_path, output_dir, dpi)\u001b[0m\n\u001b[1;32m     15\u001b[0m     os\u001b[38;5;241m.\u001b[39mmakedirs(output_dir)\n\u001b[1;32m     17\u001b[0m \u001b[38;5;66;03m# pages será una lista de PIL Images\u001b[39;00m\n\u001b[0;32m---> 18\u001b[0m pages \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_from_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdpi\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     20\u001b[0m image_paths \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     21\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, page \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(pages):\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot_ml/lib/python3.10/site-packages/pdf2image/pdf2image.py:127\u001b[0m, in \u001b[0;36mconvert_from_path\u001b[0;34m(pdf_path, dpi, output_folder, first_page, last_page, fmt, jpegopt, thread_count, userpw, ownerpw, use_cropbox, strict, transparent, single_file, output_file, poppler_path, grayscale, size, paths_only, use_pdftocairo, timeout, hide_annotations)\u001b[0m\n\u001b[1;32m    124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(poppler_path, PurePath):\n\u001b[1;32m    125\u001b[0m     poppler_path \u001b[38;5;241m=\u001b[39m poppler_path\u001b[38;5;241m.\u001b[39mas_posix()\n\u001b[0;32m--> 127\u001b[0m page_count \u001b[38;5;241m=\u001b[39m \u001b[43mpdfinfo_from_path\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    128\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpdf_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muserpw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mownerpw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpoppler_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpoppler_path\u001b[49m\n\u001b[1;32m    129\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPages\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    131\u001b[0m \u001b[38;5;66;03m# We start by getting the output format, the buffer processing function and if we need pdftocairo\u001b[39;00m\n\u001b[1;32m    132\u001b[0m parsed_fmt, final_extension, parse_buffer_func, use_pdfcairo_format \u001b[38;5;241m=\u001b[39m _parse_format(\n\u001b[1;32m    133\u001b[0m     fmt, grayscale\n\u001b[1;32m    134\u001b[0m )\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot_ml/lib/python3.10/site-packages/pdf2image/pdf2image.py:611\u001b[0m, in \u001b[0;36mpdfinfo_from_path\u001b[0;34m(pdf_path, userpw, ownerpw, poppler_path, rawdates, timeout, first_page, last_page)\u001b[0m\n\u001b[1;32m    607\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFInfoNotInstalledError(\n\u001b[1;32m    608\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count. Is poppler installed and in PATH?\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    609\u001b[0m     )\n\u001b[1;32m    610\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m:\n\u001b[0;32m--> 611\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m PDFPageCountError(\n\u001b[1;32m    612\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to get page count.\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00merr\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mutf8\u001b[39m\u001b[38;5;124m'\u001b[39m,\u001b[38;5;250m \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m'\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    613\u001b[0m     )\n",
      "\u001b[0;31mPDFPageCountError\u001b[0m: Unable to get page count.\nSyntax Warning: May not be a PDF file (continuing anyway)\nSyntax Error: Couldn't find trailer dictionary\nSyntax Error: Couldn't find trailer dictionary\nSyntax Error: Couldn't read xref table\n"
     ]
    }
   ],
   "source": [
    "def process_pdf_for_tables(pdf_path, base_output_dir=\"output_tables\", dpi=400):\n",
    "    \"\"\"\n",
    "    Convierte PDF a imágenes, detecta tablas en cada página y recorta.\n",
    "    \"\"\"\n",
    "    # 1) Convertir a imágenes\n",
    "    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    pages_dir = os.path.join(base_output_dir, pdf_name, \"pages\")\n",
    "    tables_dir = os.path.join(base_output_dir, pdf_name, \"tables\")\n",
    "\n",
    "    page_images = convert_pdf_to_images(pdf_path, pages_dir, dpi=dpi)\n",
    "\n",
    "    all_tables = []  # Para almacenar info de cada tabla\n",
    "    for page_image in page_images:\n",
    "        # 2) Detectar tablas\n",
    "        detections = detect_tables_in_image(page_image, confidence_threshold=0.3)\n",
    "        # 3) Recortar cada tabla detectada\n",
    "        page_id = os.path.splitext(os.path.basename(page_image))[0]  # \"page_1\"\n",
    "        page_tables_dir = os.path.join(tables_dir, page_id)\n",
    "        table_paths = crop_table_images(page_image, detections, page_tables_dir)\n",
    "\n",
    "        # Podrías almacenar metadatos (por ejemplo, la bounding box, etc.)\n",
    "        for tpath, det in zip(table_paths, detections):\n",
    "            all_tables.append({\n",
    "                \"pdf_name\": pdf_name,\n",
    "                \"page\": page_id,\n",
    "                \"score\": det[\"score\"],\n",
    "                \"box\": det[\"box\"],\n",
    "                \"table_image\": tpath\n",
    "            })\n",
    "\n",
    "    return all_tables\n",
    "\n",
    "# Ejemplo de ejecución\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file = \"/home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/Mazda\" \n",
    "    result_tables = process_pdf_for_tables(pdf_file, base_output_dir=\"l200_output\", dpi=400)\n",
    "    print(\"Tablas detectadas:\", result_tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "# Configuración inicial del modelo (mantenemos esto igual)\n",
    "model_name = \"microsoft/table-transformer-detection\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name, revision=\"no_timm\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(model_name, revision=\"no_timm\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Función para convertir PDF a imágenes (la misma)\n",
    "def convert_pdf_to_images(pdf_path, output_dir, dpi=400):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "    image_paths = []\n",
    "    for i, page in enumerate(pages):\n",
    "        image_name = f\"page_{i+1}.png\"\n",
    "        out_path = os.path.join(output_dir, image_name)\n",
    "        page.save(out_path, \"PNG\")\n",
    "        image_paths.append(out_path)\n",
    "    return image_paths\n",
    "\n",
    "# Función para detectar tablas (la misma)\n",
    "def detect_tables_in_image(image_path, confidence_threshold=0.3):\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    result = processor.post_process_object_detection(outputs, threshold=confidence_threshold)[0]\n",
    "    detections = []\n",
    "    for score, label, box in zip(result[\"scores\"], result[\"labels\"], result[\"boxes\"]):\n",
    "        if label == 1:\n",
    "            detections.append({\n",
    "                \"score\": float(score.cpu().numpy()),\n",
    "                \"box\": [float(x) for x in box.cpu().numpy()]\n",
    "            })\n",
    "    return detections\n",
    "\n",
    "# Función para recortar tablas (la misma)\n",
    "def crop_table_images(image_path, detections, output_dir):\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    table_paths = []\n",
    "    for i, det in enumerate(detections):\n",
    "        xmin, ymin, xmax, ymax = det[\"box\"]\n",
    "        cropped = image.crop((xmin, ymin, xmax, ymax))\n",
    "        table_path = os.path.join(output_dir, f\"table_{i+1}.png\")\n",
    "        cropped.save(table_path, \"PNG\")\n",
    "        table_paths.append(table_path)\n",
    "    return table_paths\n",
    "\n",
    "# Función modificada para procesar múltiples PDFs\n",
    "def process_all_pdfs(root_dir, base_output_dir=\"output_tables\", dpi=400):\n",
    "    all_tables = []\n",
    "    \n",
    "    # Recorrer recursivamente todos los directorios\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.pdf'):\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    print(f\"Procesando: {pdf_path}\")\n",
    "                    # Procesar cada PDF\n",
    "                    pdf_name = os.path.splitext(file)[0]\n",
    "                    pages_dir = os.path.join(base_output_dir, pdf_name, \"pages\")\n",
    "                    tables_dir = os.path.join(base_output_dir, pdf_name, \"tables\")\n",
    "                    \n",
    "                    # Convertir a imágenes\n",
    "                    page_images = convert_pdf_to_images(pdf_path, pages_dir, dpi)\n",
    "                    \n",
    "                    # Procesar cada página\n",
    "                    for page_image in page_images:\n",
    "                        detections = detect_tables_in_image(page_image)\n",
    "                        page_id = os.path.splitext(os.path.basename(page_image))[0]\n",
    "                        page_tables_dir = os.path.join(tables_dir, page_id)\n",
    "                        table_paths = crop_table_images(page_image, detections, page_tables_dir)\n",
    "                        \n",
    "                        # Guardar metadatos\n",
    "                        for tpath, det in zip(table_paths, detections):\n",
    "                            all_tables.append({\n",
    "                                \"pdf_name\": pdf_name,\n",
    "                                \"page\": page_id,\n",
    "                                \"table_image\": tpath,\n",
    "                                \"metadata\": det\n",
    "                            })\n",
    "                            \n",
    "                except Exception as e:\n",
    "                    print(f\"Error procesando {pdf_path}: {str(e)}\")\n",
    "    \n",
    "    return all_tables\n",
    "\n",
    "# Ejecución principal\n",
    "if __name__ == \"__main__\":\n",
    "    # Especificar el directorio raíz que contiene tus carpetas con PDFs\n",
    "    root_directory = \"/home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars\"\n",
    "    \n",
    "    # Procesar todos los PDFs\n",
    "    results = process_all_pdfs(\n",
    "        root_dir=root_directory,\n",
    "        base_output_dir=\"pdf_a_images\",\n",
    "        dpi=400\n",
    "    )\n",
    "    \n",
    "    print(f\"Procesamiento completado. Tablas detectadas: {len(results)}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
