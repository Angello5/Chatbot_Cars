{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Conversion de PDF a imagenes \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from pdf2image import convert_from_path\n",
    "\n",
    "def convert_pdf_to_images(pdf_path, output_dir, dpi=400):\n",
    "    \"\"\"\n",
    "    Convierte todas las p√°ginas de un PDF a im√°genes PNG.\n",
    "    Args:\n",
    "        pdf_path (str): Ruta al archivo PDF.\n",
    "        output_dir (str): Carpeta donde se guardar√°n las im√°genes.\n",
    "        dpi (int): Resoluci√≥n para la conversi√≥n. 300 suele ser un buen valor.\n",
    "    Returns:\n",
    "        List[str]: Lista de rutas a las im√°genes generadas.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    # pages ser√° una lista de PIL Images\n",
    "    pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "\n",
    "    image_paths = []\n",
    "    for i, page in enumerate(pages):\n",
    "        image_name = f\"page_{i+1}.png\"\n",
    "        out_path = os.path.join(output_dir, image_name)\n",
    "        # Guardar la imagen en PNG\n",
    "        page.save(out_path, \"PNG\")\n",
    "        image_paths.append(out_path)\n",
    "\n",
    "    return image_paths\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Carga el modelo de TATR de Hugging Face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from PIL import Image\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "model_name = \"microsoft/table-transformer-detection\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name, revision = \"no_timm\")  #no_timm se usa para evitar problemas \n",
    "model = AutoModelForObjectDetection.from_pretrained(model_name, revision = \"no_timm\")\n",
    "\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deteccion de tablas en cada imagen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def detect_tables_in_image(image_path, confidence_threshold=0.3):\n",
    "    \"\"\"\n",
    "    Detecta tablas en una imagen usando Table Transformer (detecci√≥n).\n",
    "    Args:\n",
    "        image_path (str): Ruta a la imagen PNG/JPG.\n",
    "        confidence_threshold (float): Umbral de confianza para filtrar predicciones.\n",
    "    Returns:\n",
    "        List[dict]: Lista de tablas detectadas, cada dict contiene 'score' y 'box' con coords (xmin, ymin, xmax, ymax).\n",
    "    \"\"\"\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    # Preprocesar la imagen\n",
    "    inputs = processor(images=image, return_tensors=\"pt\").to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(**inputs)\n",
    "    # Postprocesar\n",
    "    result = processor.post_process_object_detection(outputs, threshold=confidence_threshold)[0]\n",
    "\n",
    "    detections = []\n",
    "    for score, label, box in zip(result[\"scores\"], result[\"labels\"], result[\"boxes\"]):\n",
    "        if label == 1:  # 1 es la clase 'table' en este modelo\n",
    "            # box es [xmin, ymin, xmax, ymax]\n",
    "            det = {\n",
    "                \"score\": float(score.cpu().numpy()),\n",
    "                \"box\": [float(x) for x in box.cpu().numpy()]\n",
    "            }\n",
    "            detections.append(det)\n",
    "    return detections\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def crop_table_images(image_path, detections, output_dir):\n",
    "    \"\"\"\n",
    "    Recorta y guarda las regiones de tabla detectadas en 'detections'.\n",
    "    Args:\n",
    "        image_path (str): Ruta a la imagen original.\n",
    "        detections (List[dict]): Lista de tablas con su 'box'.\n",
    "        output_dir (str): Carpeta donde guardar los recortes.\n",
    "    Returns:\n",
    "        List[str]: Rutas de las im√°genes recortadas de cada tabla.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    table_paths = []\n",
    "    for i, det in enumerate(detections):\n",
    "        box = det[\"box\"]  # [xmin, ymin, xmax, ymax]\n",
    "        xmin, ymin, xmax, ymax = box\n",
    "        # Recortar\n",
    "        cropped = image.crop((xmin, ymin, xmax, ymax))\n",
    "        table_path = os.path.join(output_dir, f\"table_{i+1}.png\")\n",
    "        cropped.save(table_path, \"PNG\")\n",
    "        table_paths.append(table_path)\n",
    "    return table_paths\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_pdf_for_tables(pdf_path, base_output_dir=\"output_tables\", dpi=400):\n",
    "    \"\"\"\n",
    "    Convierte PDF a im√°genes, detecta tablas en cada p√°gina y recorta.\n",
    "    \"\"\"\n",
    "    # 1) Convertir a im√°genes\n",
    "    pdf_name = os.path.splitext(os.path.basename(pdf_path))[0]\n",
    "    pages_dir = os.path.join(base_output_dir, pdf_name, \"pages\")\n",
    "    tables_dir = os.path.join(base_output_dir, pdf_name, \"tables\")\n",
    "\n",
    "    page_images = convert_pdf_to_images(pdf_path, pages_dir, dpi=dpi)\n",
    "\n",
    "    all_tables = []  # Para almacenar info de cada tabla\n",
    "    for page_image in page_images:\n",
    "        # 2) Detectar tablas\n",
    "        detections = detect_tables_in_image(page_image, confidence_threshold=0.3)\n",
    "        # 3) Recortar cada tabla detectada\n",
    "        page_id = os.path.splitext(os.path.basename(page_image))[0]  # \"page_1\"\n",
    "        page_tables_dir = os.path.join(tables_dir, page_id)\n",
    "        table_paths = crop_table_images(page_image, detections, page_tables_dir)\n",
    "\n",
    "        # Podr√≠as almacenar metadatos (por ejemplo, la bounding box, etc.)\n",
    "        for tpath, det in zip(table_paths, detections):\n",
    "            all_tables.append({\n",
    "                \"pdf_name\": pdf_name,\n",
    "                \"page\": page_id,\n",
    "                \"score\": det[\"score\"],\n",
    "                \"box\": det[\"box\"],\n",
    "                \"table_image\": tpath\n",
    "            })\n",
    "\n",
    "    return all_tables\n",
    "\n",
    "# Ejemplo de ejecuci√≥n\n",
    "if __name__ == \"__main__\":\n",
    "    pdf_file = \"/home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/Mazda\" \n",
    "    result_tables = process_pdf_for_tables(pdf_file, base_output_dir=\"l200_output\", dpi=400)\n",
    "    print(\"Tablas detectadas:\", result_tables)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import json\n",
    "from pdf2image import convert_from_path\n",
    "from PIL import Image\n",
    "import torch\n",
    "from transformers import AutoImageProcessor, AutoModelForObjectDetection\n",
    "\n",
    "# Configuraci√≥n del modelo (igual que antes)\n",
    "model_name = \"microsoft/table-transformer-detection\"\n",
    "processor = AutoImageProcessor.from_pretrained(model_name, revision=\"no_timm\")\n",
    "model = AutoModelForObjectDetection.from_pretrained(model_name, revision=\"no_timm\")\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "model.to(device)\n",
    "model.eval()\n",
    "\n",
    "# Funci√≥n para recolectar todas las im√°genes procesadas\n",
    "def collect_processed_images(base_output_dir):\n",
    "    \"\"\"Recolecta todas las rutas de im√°genes procesadas para Label Studio\"\"\"\n",
    "    image_data = []\n",
    "    \n",
    "    for root, dirs, files in os.walk(base_output_dir):\n",
    "        if \"pages\" in root:  # Solo buscamos en directorios de p√°ginas\n",
    "            for file in files:\n",
    "                if file.lower().endswith('.png'):\n",
    "                    full_path = os.path.abspath(os.path.join(root, file))\n",
    "                    image_data.append({\n",
    "                        \"image\": full_path,\n",
    "                        \"pdf_name\": os.path.basename(os.path.dirname(os.path.dirname(root))),\n",
    "                        \"original_pdf\": os.path.join(\n",
    "                            os.path.dirname(os.path.dirname(root)),\n",
    "                            \"original\",\n",
    "                            os.path.basename(root) + \".pdf\"  # Asumiendo que guardas los PDFs originales\n",
    "                        )\n",
    "                    })\n",
    "    return image_data\n",
    "\n",
    "# Funci√≥n principal modificada\n",
    "def process_all_pdfs(root_dir, base_output_dir=\"output_tables\", dpi=400):\n",
    "    all_tables = []\n",
    "    \n",
    "    # Primero procesamos todos los PDFs\n",
    "    for root, dirs, files in os.walk(root_dir):\n",
    "        for file in files:\n",
    "            if file.lower().endswith('.pdf'):\n",
    "                pdf_path = os.path.join(root, file)\n",
    "                try:\n",
    "                    print(f\"üîç Procesando: {pdf_path}\")\n",
    "                    pdf_name = os.path.splitext(file)[0]\n",
    "                    output_pdf_dir = os.path.join(base_output_dir, pdf_name)\n",
    "                    \n",
    "                    # Convertir PDF a im√°genes\n",
    "                    pages_dir = os.path.join(output_pdf_dir, \"pages\")\n",
    "                    convert_pdf_to_images(pdf_path, pages_dir, dpi)\n",
    "                    \n",
    "                    # Opcional: Guardar una copia del PDF original\n",
    "                    original_pdf_dir = os.path.join(output_pdf_dir, \"original\")\n",
    "                    os.makedirs(original_pdf_dir, exist_ok=True)\n",
    "                    os.system(f'cp \"{pdf_path}\" \"{original_pdf_dir}\"')\n",
    "\n",
    "                except Exception as e:\n",
    "                    print(f\"‚ùå Error procesando {pdf_path}: {str(e)}\")\n",
    "    \n",
    "    # Luego generamos el JSON para Label Studio\n",
    "    label_studio_data = []\n",
    "    images = collect_processed_images(base_output_dir)\n",
    "    \n",
    "    for img in images:\n",
    "        label_studio_data.append({\n",
    "            \"data\": {\n",
    "                \"image\": img[\"image\"],\n",
    "                \"pdf_info\": {\n",
    "                    \"name\": img[\"pdf_name\"],\n",
    "                    \"original_path\": img[\"original_pdf\"]\n",
    "                }\n",
    "            }\n",
    "        })\n",
    "    \n",
    "    # Guardar el JSON\n",
    "    json_path = os.path.join(base_output_dir, \"label_studio_import.json\")\n",
    "    with open(json_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(label_studio_data, f, indent=4, ensure_ascii=False)\n",
    "    \n",
    "    print(f\"\\n‚úÖ JSON generado con {len(label_studio_data)} im√°genes en: {json_path}\")\n",
    "    return all_tables\n",
    "\n",
    "# Funciones auxiliares (las mismas que antes)\n",
    "def convert_pdf_to_images(pdf_path, output_dir, dpi=400):\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    pages = convert_from_path(pdf_path, dpi=dpi)\n",
    "    return [page.save(os.path.join(output_dir, f\"page_{i+1}.png\"), \"PNG\") for i, page in enumerate(pages)]\n",
    "\n",
    "def detect_tables_in_image(image_path, confidence_threshold=0.3):\n",
    "    # (Implementaci√≥n anterior)\n",
    "    pass\n",
    "\n",
    "def crop_table_images(image_path, detections, output_dir):\n",
    "    # (Implementaci√≥n anterior)\n",
    "    pass\n",
    "\n",
    "# Ejecuci√≥n\n",
    "if __name__ == \"__main__\":\n",
    "    # Configuraci√≥n\n",
    "    input_root = \"/home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars\"\n",
    "    output_dir = \"images_pdf\"\n",
    "    \n",
    "    # Procesar todo y generar JSON\n",
    "    process_all_pdfs(\n",
    "        root_dir=input_root,\n",
    "        base_output_dir=output_dir,\n",
    "        dpi=400\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
