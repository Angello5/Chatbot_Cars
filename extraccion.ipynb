{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import pytesseract\n",
    "from transformers import LayoutLMv3Processor, LayoutLMForTokenClassification\n",
    "from PIL import Image \n",
    "import torch\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "modelo = \"microsoft/layoutlmv3-base\"\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You are using a model of type layoutlmv3 to instantiate a model of type layoutlm. This is not supported for all configurations of models and can yield errors.\n",
      "Some weights of LayoutLMForTokenClassification were not initialized from the model checkpoint at microsoft/layoutlmv3-base and are newly initialized: ['classifier.bias', 'classifier.weight', 'layoutlm.embeddings.LayerNorm.bias', 'layoutlm.embeddings.LayerNorm.weight', 'layoutlm.embeddings.h_position_embeddings.weight', 'layoutlm.embeddings.position_embeddings.weight', 'layoutlm.embeddings.token_type_embeddings.weight', 'layoutlm.embeddings.w_position_embeddings.weight', 'layoutlm.embeddings.word_embeddings.weight', 'layoutlm.embeddings.x_position_embeddings.weight', 'layoutlm.embeddings.y_position_embeddings.weight', 'layoutlm.encoder.layer.0.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.0.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.0.attention.output.dense.bias', 'layoutlm.encoder.layer.0.attention.output.dense.weight', 'layoutlm.encoder.layer.0.attention.self.key.bias', 'layoutlm.encoder.layer.0.attention.self.key.weight', 'layoutlm.encoder.layer.0.attention.self.query.bias', 'layoutlm.encoder.layer.0.attention.self.query.weight', 'layoutlm.encoder.layer.0.attention.self.value.bias', 'layoutlm.encoder.layer.0.attention.self.value.weight', 'layoutlm.encoder.layer.0.intermediate.dense.bias', 'layoutlm.encoder.layer.0.intermediate.dense.weight', 'layoutlm.encoder.layer.0.output.LayerNorm.bias', 'layoutlm.encoder.layer.0.output.LayerNorm.weight', 'layoutlm.encoder.layer.0.output.dense.bias', 'layoutlm.encoder.layer.0.output.dense.weight', 'layoutlm.encoder.layer.1.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.1.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.1.attention.output.dense.bias', 'layoutlm.encoder.layer.1.attention.output.dense.weight', 'layoutlm.encoder.layer.1.attention.self.key.bias', 'layoutlm.encoder.layer.1.attention.self.key.weight', 'layoutlm.encoder.layer.1.attention.self.query.bias', 'layoutlm.encoder.layer.1.attention.self.query.weight', 'layoutlm.encoder.layer.1.attention.self.value.bias', 'layoutlm.encoder.layer.1.attention.self.value.weight', 'layoutlm.encoder.layer.1.intermediate.dense.bias', 'layoutlm.encoder.layer.1.intermediate.dense.weight', 'layoutlm.encoder.layer.1.output.LayerNorm.bias', 'layoutlm.encoder.layer.1.output.LayerNorm.weight', 'layoutlm.encoder.layer.1.output.dense.bias', 'layoutlm.encoder.layer.1.output.dense.weight', 'layoutlm.encoder.layer.10.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.10.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.10.attention.output.dense.bias', 'layoutlm.encoder.layer.10.attention.output.dense.weight', 'layoutlm.encoder.layer.10.attention.self.key.bias', 'layoutlm.encoder.layer.10.attention.self.key.weight', 'layoutlm.encoder.layer.10.attention.self.query.bias', 'layoutlm.encoder.layer.10.attention.self.query.weight', 'layoutlm.encoder.layer.10.attention.self.value.bias', 'layoutlm.encoder.layer.10.attention.self.value.weight', 'layoutlm.encoder.layer.10.intermediate.dense.bias', 'layoutlm.encoder.layer.10.intermediate.dense.weight', 'layoutlm.encoder.layer.10.output.LayerNorm.bias', 'layoutlm.encoder.layer.10.output.LayerNorm.weight', 'layoutlm.encoder.layer.10.output.dense.bias', 'layoutlm.encoder.layer.10.output.dense.weight', 'layoutlm.encoder.layer.11.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.11.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.11.attention.output.dense.bias', 'layoutlm.encoder.layer.11.attention.output.dense.weight', 'layoutlm.encoder.layer.11.attention.self.key.bias', 'layoutlm.encoder.layer.11.attention.self.key.weight', 'layoutlm.encoder.layer.11.attention.self.query.bias', 'layoutlm.encoder.layer.11.attention.self.query.weight', 'layoutlm.encoder.layer.11.attention.self.value.bias', 'layoutlm.encoder.layer.11.attention.self.value.weight', 'layoutlm.encoder.layer.11.intermediate.dense.bias', 'layoutlm.encoder.layer.11.intermediate.dense.weight', 'layoutlm.encoder.layer.11.output.LayerNorm.bias', 'layoutlm.encoder.layer.11.output.LayerNorm.weight', 'layoutlm.encoder.layer.11.output.dense.bias', 'layoutlm.encoder.layer.11.output.dense.weight', 'layoutlm.encoder.layer.2.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.2.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.2.attention.output.dense.bias', 'layoutlm.encoder.layer.2.attention.output.dense.weight', 'layoutlm.encoder.layer.2.attention.self.key.bias', 'layoutlm.encoder.layer.2.attention.self.key.weight', 'layoutlm.encoder.layer.2.attention.self.query.bias', 'layoutlm.encoder.layer.2.attention.self.query.weight', 'layoutlm.encoder.layer.2.attention.self.value.bias', 'layoutlm.encoder.layer.2.attention.self.value.weight', 'layoutlm.encoder.layer.2.intermediate.dense.bias', 'layoutlm.encoder.layer.2.intermediate.dense.weight', 'layoutlm.encoder.layer.2.output.LayerNorm.bias', 'layoutlm.encoder.layer.2.output.LayerNorm.weight', 'layoutlm.encoder.layer.2.output.dense.bias', 'layoutlm.encoder.layer.2.output.dense.weight', 'layoutlm.encoder.layer.3.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.3.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.3.attention.output.dense.bias', 'layoutlm.encoder.layer.3.attention.output.dense.weight', 'layoutlm.encoder.layer.3.attention.self.key.bias', 'layoutlm.encoder.layer.3.attention.self.key.weight', 'layoutlm.encoder.layer.3.attention.self.query.bias', 'layoutlm.encoder.layer.3.attention.self.query.weight', 'layoutlm.encoder.layer.3.attention.self.value.bias', 'layoutlm.encoder.layer.3.attention.self.value.weight', 'layoutlm.encoder.layer.3.intermediate.dense.bias', 'layoutlm.encoder.layer.3.intermediate.dense.weight', 'layoutlm.encoder.layer.3.output.LayerNorm.bias', 'layoutlm.encoder.layer.3.output.LayerNorm.weight', 'layoutlm.encoder.layer.3.output.dense.bias', 'layoutlm.encoder.layer.3.output.dense.weight', 'layoutlm.encoder.layer.4.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.4.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.4.attention.output.dense.bias', 'layoutlm.encoder.layer.4.attention.output.dense.weight', 'layoutlm.encoder.layer.4.attention.self.key.bias', 'layoutlm.encoder.layer.4.attention.self.key.weight', 'layoutlm.encoder.layer.4.attention.self.query.bias', 'layoutlm.encoder.layer.4.attention.self.query.weight', 'layoutlm.encoder.layer.4.attention.self.value.bias', 'layoutlm.encoder.layer.4.attention.self.value.weight', 'layoutlm.encoder.layer.4.intermediate.dense.bias', 'layoutlm.encoder.layer.4.intermediate.dense.weight', 'layoutlm.encoder.layer.4.output.LayerNorm.bias', 'layoutlm.encoder.layer.4.output.LayerNorm.weight', 'layoutlm.encoder.layer.4.output.dense.bias', 'layoutlm.encoder.layer.4.output.dense.weight', 'layoutlm.encoder.layer.5.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.5.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.5.attention.output.dense.bias', 'layoutlm.encoder.layer.5.attention.output.dense.weight', 'layoutlm.encoder.layer.5.attention.self.key.bias', 'layoutlm.encoder.layer.5.attention.self.key.weight', 'layoutlm.encoder.layer.5.attention.self.query.bias', 'layoutlm.encoder.layer.5.attention.self.query.weight', 'layoutlm.encoder.layer.5.attention.self.value.bias', 'layoutlm.encoder.layer.5.attention.self.value.weight', 'layoutlm.encoder.layer.5.intermediate.dense.bias', 'layoutlm.encoder.layer.5.intermediate.dense.weight', 'layoutlm.encoder.layer.5.output.LayerNorm.bias', 'layoutlm.encoder.layer.5.output.LayerNorm.weight', 'layoutlm.encoder.layer.5.output.dense.bias', 'layoutlm.encoder.layer.5.output.dense.weight', 'layoutlm.encoder.layer.6.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.6.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.6.attention.output.dense.bias', 'layoutlm.encoder.layer.6.attention.output.dense.weight', 'layoutlm.encoder.layer.6.attention.self.key.bias', 'layoutlm.encoder.layer.6.attention.self.key.weight', 'layoutlm.encoder.layer.6.attention.self.query.bias', 'layoutlm.encoder.layer.6.attention.self.query.weight', 'layoutlm.encoder.layer.6.attention.self.value.bias', 'layoutlm.encoder.layer.6.attention.self.value.weight', 'layoutlm.encoder.layer.6.intermediate.dense.bias', 'layoutlm.encoder.layer.6.intermediate.dense.weight', 'layoutlm.encoder.layer.6.output.LayerNorm.bias', 'layoutlm.encoder.layer.6.output.LayerNorm.weight', 'layoutlm.encoder.layer.6.output.dense.bias', 'layoutlm.encoder.layer.6.output.dense.weight', 'layoutlm.encoder.layer.7.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.7.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.7.attention.output.dense.bias', 'layoutlm.encoder.layer.7.attention.output.dense.weight', 'layoutlm.encoder.layer.7.attention.self.key.bias', 'layoutlm.encoder.layer.7.attention.self.key.weight', 'layoutlm.encoder.layer.7.attention.self.query.bias', 'layoutlm.encoder.layer.7.attention.self.query.weight', 'layoutlm.encoder.layer.7.attention.self.value.bias', 'layoutlm.encoder.layer.7.attention.self.value.weight', 'layoutlm.encoder.layer.7.intermediate.dense.bias', 'layoutlm.encoder.layer.7.intermediate.dense.weight', 'layoutlm.encoder.layer.7.output.LayerNorm.bias', 'layoutlm.encoder.layer.7.output.LayerNorm.weight', 'layoutlm.encoder.layer.7.output.dense.bias', 'layoutlm.encoder.layer.7.output.dense.weight', 'layoutlm.encoder.layer.8.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.8.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.8.attention.output.dense.bias', 'layoutlm.encoder.layer.8.attention.output.dense.weight', 'layoutlm.encoder.layer.8.attention.self.key.bias', 'layoutlm.encoder.layer.8.attention.self.key.weight', 'layoutlm.encoder.layer.8.attention.self.query.bias', 'layoutlm.encoder.layer.8.attention.self.query.weight', 'layoutlm.encoder.layer.8.attention.self.value.bias', 'layoutlm.encoder.layer.8.attention.self.value.weight', 'layoutlm.encoder.layer.8.intermediate.dense.bias', 'layoutlm.encoder.layer.8.intermediate.dense.weight', 'layoutlm.encoder.layer.8.output.LayerNorm.bias', 'layoutlm.encoder.layer.8.output.LayerNorm.weight', 'layoutlm.encoder.layer.8.output.dense.bias', 'layoutlm.encoder.layer.8.output.dense.weight', 'layoutlm.encoder.layer.9.attention.output.LayerNorm.bias', 'layoutlm.encoder.layer.9.attention.output.LayerNorm.weight', 'layoutlm.encoder.layer.9.attention.output.dense.bias', 'layoutlm.encoder.layer.9.attention.output.dense.weight', 'layoutlm.encoder.layer.9.attention.self.key.bias', 'layoutlm.encoder.layer.9.attention.self.key.weight', 'layoutlm.encoder.layer.9.attention.self.query.bias', 'layoutlm.encoder.layer.9.attention.self.query.weight', 'layoutlm.encoder.layer.9.attention.self.value.bias', 'layoutlm.encoder.layer.9.attention.self.value.weight', 'layoutlm.encoder.layer.9.intermediate.dense.bias', 'layoutlm.encoder.layer.9.intermediate.dense.weight', 'layoutlm.encoder.layer.9.output.LayerNorm.bias', 'layoutlm.encoder.layer.9.output.LayerNorm.weight', 'layoutlm.encoder.layer.9.output.dense.bias', 'layoutlm.encoder.layer.9.output.dense.weight', 'layoutlm.pooler.dense.bias', 'layoutlm.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "processor = LayoutLMv3Processor.from_pretrained(modelo, apply_ocr = False)\n",
    "model = LayoutLMForTokenClassification.from_pretrained(modelo).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "ruta_imagenes = \"/home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/\"\n",
    "ruta_salida = \"/home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/datos_extraidos\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extraer_datos(imagen_path):\n",
    "    try:\n",
    "        imagen = Image.open(imagen_path).convert(\"RGB\")\n",
    "        \n",
    "        # Usamos pytesseract para OCR\n",
    "        palabras = pytesseract.image_to_data(imagen, lang='spa', output_type=pytesseract.Output.DICT)\n",
    "        \n",
    "        # Filtrar solo las palabras no vacías\n",
    "        palabras_filtradas = []\n",
    "        boxes_filtrados = []\n",
    "        \n",
    "        for i in range(len(palabras['text'])):\n",
    "            if palabras['text'][i].strip() != \"\":\n",
    "                palabras_filtradas.append(palabras['text'][i])\n",
    "                # Convertir a formato esperado por LayoutLMv3: [x_izq, y_sup, x_der, y_inf]\n",
    "                x_izq = palabras['left'][i]\n",
    "                y_sup = palabras['top'][i]\n",
    "                x_der = x_izq + palabras['width'][i]\n",
    "                y_inf = y_sup + palabras['height'][i]\n",
    "                boxes_filtrados.append([x_izq, y_sup, x_der, y_inf])\n",
    "        \n",
    "        if not palabras_filtradas:\n",
    "            print(f\"No se encontró texto en {imagen_path}\")\n",
    "            return {\"error\": \"No se encontró texto en la imagen\"}\n",
    "        \n",
    "        # Procesamiento con LayoutLMv3\n",
    "        encoding = processor(\n",
    "            imagen, \n",
    "            words=palabras_filtradas,  # Usar palabras en lugar de texto\n",
    "            boxes=boxes_filtrados,  # Usar cajas en formato correcto\n",
    "            return_tensors=\"pt\"\n",
    "        )\n",
    "        \n",
    "        encoding = {k:v.to(device) for k,v in encoding.items()}\n",
    "        \n",
    "        # Inferencia del modelo\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**encoding)\n",
    "            \n",
    "        logits = outputs.logits\n",
    "        predictions = logits.argmax(-1).squeeze().tolist()\n",
    "        \n",
    "        # Asegurarse de que predictions es una lista\n",
    "        if not isinstance(predictions, list):\n",
    "            predictions = [predictions]\n",
    "        \n",
    "        # Procesar las predicciones\n",
    "        resultado = {}\n",
    "        token_ids = encoding['input_ids'][0].tolist()\n",
    "        tokens = processor.tokenizer.convert_ids_to_tokens(token_ids)\n",
    "        \n",
    "        # Mapear tokens a palabras originales\n",
    "        palabra_actual = \"\"\n",
    "        etiqueta_actual = \"\"\n",
    "        for token, pred_id in zip(tokens, predictions):\n",
    "            # Ignorar tokens especiales como [CLS], [SEP], etc.\n",
    "            if token.startswith(\"##\"):\n",
    "                palabra_actual += token[2:]\n",
    "            elif token in processor.tokenizer.all_special_tokens:\n",
    "                continue\n",
    "            else:\n",
    "                if palabra_actual and etiqueta_actual != \"O\":\n",
    "                    if etiqueta_actual not in resultado:\n",
    "                        resultado[etiqueta_actual] = palabra_actual\n",
    "                    else:\n",
    "                        resultado[etiqueta_actual] += f\" {palabra_actual}\"\n",
    "                \n",
    "                palabra_actual = token\n",
    "                etiqueta_actual = model.config.id2label.get(pred_id, \"O\")\n",
    "        \n",
    "        # No olvidar la última palabra\n",
    "        if palabra_actual and etiqueta_actual != \"O\":\n",
    "            if etiqueta_actual not in resultado:\n",
    "                resultado[etiqueta_actual] = palabra_actual\n",
    "            else:\n",
    "                resultado[etiqueta_actual] += f\" {palabra_actual}\"\n",
    "        \n",
    "        return resultado\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Error procesando {imagen_path}: {str(e)}\")\n",
    "        return {\"error\": str(e)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/202411-02-onix-sedan-turbo-my25_297.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/202411-02-onix-sedan-turbo-my25_297.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/CATALOGO_RAV4_PERU_0_180.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/CATALOGO_RAV4_PERU_0_180.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/CATALOGO_4RUNNER_PERU_0_100.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/CATALOGO_4RUNNER_PERU_0_100.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/ficha-tecnica_suzuki-pe_s-presso_555.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/ficha-tecnica_suzuki-pe_s-presso_555.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/FichaTecnica-Teramont-2024_516.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/FichaTecnica-Teramont-2024_516.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/ficha-tecnica-h6-hev_620.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/ficha-tecnica-h6-hev_620.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/kwid-ft_434.png\n",
      "No se encontró texto en /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/kwid-ft_434.png\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/kwid-ft_417.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/kwid-ft_417.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/2023-12-05-ficha-cx-60-vertical_204.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/2023-12-05-ficha-cx-60-vertical_204.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/FICHA-TECNICA-OKAVANGO-1_5T-SIGNATURE-MHEV_147.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/FICHA-TECNICA-OKAVANGO-1_5T-SIGNATURE-MHEV_147.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/CATALOGO_4RUNNER_PERU_0_103.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/CATALOGO_4RUNNER_PERU_0_103.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/ficha-T5-EV-2_164.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/ficha-T5-EV-2_164.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/202411-04-groove-my25_71.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/202411-04-groove-my25_71.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/catalogo-corolla-cross-2024-consolidado_155.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/catalogo-corolla-cross-2024-consolidado_155.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/ficha-tecnica_suzuki-pe_dzire_388.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/ficha-tecnica_suzuki-pe_dzire_388.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/FT-KONA-EV_142.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/FT-KONA-EV_142.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/oroch-ft_668.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/oroch-ft_668.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/CATALOGO_RAIZE_PERU_1_506.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/CATALOGO_RAIZE_PERU_1_506.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/catalogo-yaris-cross-2024-consolidado_527.png\n",
      "Error procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/catalogo-yaris-cross-2024-consolidado_527.png: 'words'\n",
      "Procesando /home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/2023-12-28-ficha-tecnica_stepway_554.png\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m ruta_img \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(imagenes_folder, img_file)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProcesando \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mruta_img\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 7\u001b[0m datos \u001b[38;5;241m=\u001b[39m \u001b[43mextraer_datos\u001b[49m\u001b[43m(\u001b[49m\u001b[43mruta_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m datos[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mimagen_fuente\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m img_file\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# Guarda el resultado en JSON\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[24], line 6\u001b[0m, in \u001b[0;36mextraer_datos\u001b[0;34m(imagen_path)\u001b[0m\n\u001b[1;32m      3\u001b[0m imagen \u001b[38;5;241m=\u001b[39m Image\u001b[38;5;241m.\u001b[39mopen(imagen_path)\u001b[38;5;241m.\u001b[39mconvert(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRGB\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;66;03m# Usamos pytesseract para OCR\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m palabras \u001b[38;5;241m=\u001b[39m \u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimage_to_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimagen\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mspa\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutput_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpytesseract\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Filtrar solo las palabras no vacías\u001b[39;00m\n\u001b[1;32m      9\u001b[0m palabras_filtradas \u001b[38;5;241m=\u001b[39m []\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot_ml/lib/python3.10/site-packages/pytesseract/pytesseract.py:596\u001b[0m, in \u001b[0;36mimage_to_data\u001b[0;34m(image, lang, config, nice, output_type, timeout, pandas_config)\u001b[0m\n\u001b[1;32m    593\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-c tessedit_create_tsv=1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    594\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsv\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[0;32m--> 596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m{\u001b[49m\n\u001b[1;32m    597\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mBYTES\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    598\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDATAFRAME\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mget_pandas_output\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    599\u001b[0m \u001b[43m        \u001b[49m\u001b[43margs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    600\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpandas_config\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    601\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    602\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mDICT\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mfile_to_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;130;43;01m\\t\u001b[39;49;00m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    603\u001b[0m \u001b[43m    \u001b[49m\u001b[43mOutput\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mSTRING\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    604\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m[\u001b[49m\u001b[43moutput_type\u001b[49m\u001b[43m]\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot_ml/lib/python3.10/site-packages/pytesseract/pytesseract.py:602\u001b[0m, in \u001b[0;36mimage_to_data.<locals>.<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    593\u001b[0m config \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-c tessedit_create_tsv=1 \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig\u001b[38;5;241m.\u001b[39mstrip()\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    594\u001b[0m args \u001b[38;5;241m=\u001b[39m [image, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtsv\u001b[39m\u001b[38;5;124m'\u001b[39m, lang, config, nice, timeout]\n\u001b[1;32m    596\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m {\n\u001b[1;32m    597\u001b[0m     Output\u001b[38;5;241m.\u001b[39mBYTES: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39m(args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m])),\n\u001b[1;32m    598\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDATAFRAME: \u001b[38;5;28;01mlambda\u001b[39;00m: get_pandas_output(\n\u001b[1;32m    599\u001b[0m         args \u001b[38;5;241m+\u001b[39m [\u001b[38;5;28;01mTrue\u001b[39;00m],\n\u001b[1;32m    600\u001b[0m         pandas_config,\n\u001b[1;32m    601\u001b[0m     ),\n\u001b[0;32m--> 602\u001b[0m     Output\u001b[38;5;241m.\u001b[39mDICT: \u001b[38;5;28;01mlambda\u001b[39;00m: file_to_dict(\u001b[43mrun_and_get_output\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m),\n\u001b[1;32m    603\u001b[0m     Output\u001b[38;5;241m.\u001b[39mSTRING: \u001b[38;5;28;01mlambda\u001b[39;00m: run_and_get_output(\u001b[38;5;241m*\u001b[39margs),\n\u001b[1;32m    604\u001b[0m }[output_type]()\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot_ml/lib/python3.10/site-packages/pytesseract/pytesseract.py:352\u001b[0m, in \u001b[0;36mrun_and_get_output\u001b[0;34m(image, extension, lang, config, nice, timeout, return_bytes)\u001b[0m\n\u001b[1;32m    341\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m save(image) \u001b[38;5;28;01mas\u001b[39;00m (temp_name, input_filename):\n\u001b[1;32m    342\u001b[0m     kwargs \u001b[38;5;241m=\u001b[39m {\n\u001b[1;32m    343\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minput_filename\u001b[39m\u001b[38;5;124m'\u001b[39m: input_filename,\n\u001b[1;32m    344\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m: temp_name,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    349\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtimeout\u001b[39m\u001b[38;5;124m'\u001b[39m: timeout,\n\u001b[1;32m    350\u001b[0m     }\n\u001b[0;32m--> 352\u001b[0m     \u001b[43mrun_tesseract\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    353\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _read_output(\n\u001b[1;32m    354\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mkwargs[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124moutput_filename_base\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextsep\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00mextension\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    355\u001b[0m         return_bytes,\n\u001b[1;32m    356\u001b[0m     )\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot_ml/lib/python3.10/site-packages/pytesseract/pytesseract.py:282\u001b[0m, in \u001b[0;36mrun_tesseract\u001b[0;34m(input_filename, output_filename_base, extension, lang, config, nice, timeout)\u001b[0m\n\u001b[1;32m    279\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    280\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractNotFoundError()\n\u001b[0;32m--> 282\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m timeout_manager(proc, timeout) \u001b[38;5;28;01mas\u001b[39;00m error_string:\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m proc\u001b[38;5;241m.\u001b[39mreturncode:\n\u001b[1;32m    284\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m TesseractError(proc\u001b[38;5;241m.\u001b[39mreturncode, get_errors(error_string))\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot_ml/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot_ml/lib/python3.10/site-packages/pytesseract/pytesseract.py:144\u001b[0m, in \u001b[0;36mtimeout_manager\u001b[0;34m(proc, seconds)\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    143\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m seconds:\n\u001b[0;32m--> 144\u001b[0m         \u001b[38;5;28;01myield\u001b[39;00m \u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcommunicate\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;241m1\u001b[39m]\n\u001b[1;32m    145\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[1;32m    147\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot_ml/lib/python3.10/subprocess.py:1154\u001b[0m, in \u001b[0;36mPopen.communicate\u001b[0;34m(self, input, timeout)\u001b[0m\n\u001b[1;32m   1151\u001b[0m     endtime \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1153\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m-> 1154\u001b[0m     stdout, stderr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_communicate\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mendtime\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1155\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mKeyboardInterrupt\u001b[39;00m:\n\u001b[1;32m   1156\u001b[0m     \u001b[38;5;66;03m# https://bugs.python.org/issue25942\u001b[39;00m\n\u001b[1;32m   1157\u001b[0m     \u001b[38;5;66;03m# See the detailed comment in .wait().\u001b[39;00m\n\u001b[1;32m   1158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot_ml/lib/python3.10/subprocess.py:2021\u001b[0m, in \u001b[0;36mPopen._communicate\u001b[0;34m(self, input, endtime, orig_timeout)\u001b[0m\n\u001b[1;32m   2014\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout,\n\u001b[1;32m   2015\u001b[0m                         stdout, stderr,\n\u001b[1;32m   2016\u001b[0m                         skip_check_and_raise\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2017\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(  \u001b[38;5;66;03m# Impossible :)\u001b[39;00m\n\u001b[1;32m   2018\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_check_timeout(..., skip_check_and_raise=True) \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m   2019\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfailed to raise TimeoutExpired.\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m-> 2021\u001b[0m ready \u001b[38;5;241m=\u001b[39m \u001b[43mselector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mselect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2022\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_timeout(endtime, orig_timeout, stdout, stderr)\n\u001b[1;32m   2024\u001b[0m \u001b[38;5;66;03m# XXX Rewrite these to use non-blocking I/O on the file\u001b[39;00m\n\u001b[1;32m   2025\u001b[0m \u001b[38;5;66;03m# objects; they are no longer using C stdio!\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/chatbot_ml/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_selector\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpoll\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    417\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "datos_todas_fichas = {}\n",
    "imagenes_folder = \"/home/pibezx/Documents/Proyectos/PaginaWeb_Automoviles/Chatbot_Cars/imagenes_fichas/\"\n",
    "for img_file in os.listdir(imagenes_folder):\n",
    "    if img_file.lower().endswith(\".png\"):\n",
    "        ruta_img = os.path.join(imagenes_folder, img_file)\n",
    "        print(f\"Procesando {ruta_img}\")\n",
    "        datos = extraer_datos(ruta_img)\n",
    "        datos[\"imagen_fuente\"] = img_file\n",
    "\n",
    "        # Guarda el resultado en JSON\n",
    "        with open(f\"datos_extraidos/{img_file}.json\", \"w\", encoding=\"utf-8\") as f:\n",
    "            json.dump(datos, f, ensure_ascii=False, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chatbot_ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
